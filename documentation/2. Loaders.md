# Loaders

The loader classes in nitrain help you create training batches from your dataset that can be consumed by your model during training. In the simplest case you may simply read your images from file, convert them into arrays, and then merge those arrays together to be fed into your model. However, the reality of training medical imaging AI models is often more complicated.

That's why loaders support both data augmentation via random transforms and training on only patches or slices of images via samplers. Both of those topics are discussed in-depth in their own tutorials, so here we will only go through dataset loaders themselves.

## Types of loaders

There is one main class called `DatasetLoader` that will satisfy most of your use-cases. However, if you want to use batch generation techniques specific to Keras or Pytorch then you may want to check out the `KerasLoader`or `TorchLodaer` classes.

## Creating a loader

To create a `DatasetLoader` instance, you need to pass in a nitrain dataset instance along with the desired batch size.

```python
from nitrain.datasets import FolderDataset
from nitrain.loaders import DatasetLoader

dataset = FolderDataset(base_dir='dataset',
                        x={'pattern': 't1.nii.gz'},
                        y={'file': 'participants.csv', 'column': 'age'})
loader = DatasetLoader(dataset, batch_size=12)
```

## Iterating through a loader

As mentioned in the datasets tutorial, you can iterate through the dataset class to read images and values from file. But when you iterate through images in a dataset, you will always get back lists of images. They are not combined in any way.

When you iterate through a loader, on the other hand, you will actually get a single big array where each image has been converted into an array and then combined. The dimensions of the array will be `(batch_size, image_dim1, imag_dim2, [image_dim3], 1)`.

```python
x_batch, y_batch = next(iter(loader))
# x_batch shape: (12, 128, 128, 128, 1)
```

That additional "1" dimension is added because most AI model frameworks expect you to have an extra channel dimension for your image. This can easily be disabled by setting the `expand_dims=None` argument when creating the loader.

Iterating through the loader one time will serve all of the images one time:

```python
# this will loop math.ceil(n_participants / 12) times
for x_batch, y_batch in loader:
    print(x_batch.shape)
```

So if you wanted to train a model manually on batches, you can simply loop through the loader at each epoch.

```python
for epoch in range(n_epochs):
    for x_batch, y_batch in loader:
        model.train_on_batch(x_batch, y_batch)
```

## Final word on loaders

The `DatasetLoader` class in nitrain is how you create and serve batches of data to your model during training. They work behind the scenes to efficiently read in images and get them into the correct format so that your model is not bound by IO operations. And as you will see in later tutorials, they are extremely flexible in allowing samplers and transforms.
